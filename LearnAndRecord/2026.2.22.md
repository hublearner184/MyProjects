# 2026.2.22

## 损失函数

损失函数：衡量模型输出与真实标签的差异

代价函数：归结所有样本点求平均

目标函数：Cost+Regularization（正则化项控制过拟合）

### nn.CrossEntropyLoss

nn.LogSoftmax()与nn.NLLLoss()结合，进行交叉熵运算

主要参数：weight  ignore_index  reduction

### nn.NLLLoss

实现负对数似然函数中的负号功能

### nn.BCELoss

二分类交叉熵 输入值取值在[0,1]

### nn.BCEWithLogitsLoss

结合Sigmoid与二分类交叉熵  网络最后不加Sigmoid函数

### nn.L1Loss

MAE(平均绝对误差)

计算inputs与target之差的绝对值

### nn.MSELoss

MSE(平方误差)

计算inputs与target之差的平方

主要是用于回归任务

## 优化器（optimizer）

pytorch的优化器：管理并更新模型中可学习参数的值，使得模型输出更接近真实标签

### 学习率调整

梯度下降：wi+1 = wi - LR * g(wi)

学习率控制更新的步伐

class LRScheduler   主要属性：optimizer：关联的优化器 last_epoch：记录的epoch数

base_lrs:记录初始学习率  step()：更新下一个epoch的学习率   get_lr():计算下一个epoch的学习率

#### stepLR

stepLR 等间隔调整学习率  lr = lr * γ

#### MultiStepLR

按给定间隔调整学习率主要参数

milestones：设置调整时刻数       gamma：调整系数

