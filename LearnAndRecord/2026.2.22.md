# 2026.2.22

## 损失函数

损失函数：衡量模型输出与真实标签的差异

代价函数：归结所有样本点求平均

目标函数：Cost+Regularization（正则化项控制过拟合）

### nn.CrossEntropyLoss

nn.LogSoftmax()与nn.NLLLoss()结合，进行交叉熵运算

主要参数：weight  ignore_index  reduction

### nn.NLLLoss

实现负对数似然函数中的负号功能

### nn.BCELoss

二分类交叉熵 输入值取值在[0,1]

### nn.BCEWithLogitsLoss

结合Sigmoid与二分类交叉熵  网络最后不加Sigmoid函数

### nn.L1Loss

MAE(平均绝对误差)

计算inputs与target之差的绝对值

### nn.MSELoss

MSE(平方误差)

计算inputs与target之差的平方

主要是用于回归任务

## 优化器（optimizer）

pytorch的优化器：管理并更新模型中可学习参数的值，使得模型输出更接近真实标签

### 学习率调整

梯度下降：wi+1 = wi - LR * g(wi)

学习率控制更新的步伐

class LRScheduler   主要属性：optimizer：关联的优化器 last_epoch：记录的epoch数

base_lrs:记录初始学习率  step()：更新下一个epoch的学习率   get_lr():计算下一个epoch的学习率

#### stepLR

stepLR 等间隔调整学习率  lr = lr * γ

#### MultiStepLR

按给定间隔调整学习率主要参数

milestones：设置调整时刻数       gamma：调整系数

# 2026.2.23

## 学习率

### ExponentialLR

功能：按指数衰减调整学习率

LR = LR * gamma ** epoch

gamma是指数的底

### CosineAnnealingLR

功能：余弦周期调整学习率

主要参数 T_max:下降周期   eta_min:学习率下限

### ReduceLRonPlateau

功能：监控指标，当指标不再变化则调整

### lambda自定义

## 可视化工具--TensorBoard

## Claude Code



# 2026.2.24

## 花朵分类

### 模型训练的代码框架

![image-20260224113402826](./2026.2.22.assets/image-20260224113402826.png)

### 下载数据集

https://www.robots.ox.ac.uk/~vgg/data/flowers/102/

dataset images 和 image labels

### 划分花朵的数据集

```python
#划分花朵数据集
import os
import random
if __name__ == "__main__":
#step1根据图像路径得到所有图像的列表
    img_dir = r"D:\data\flowers_data\jpg"
    img_list = [os.path.join(img_dir, name) for name in
                os.listdir(img_dir)]
    random.seed(10086)
    random.shuffle(img_list)
```

**`if __name__ == "__main__":`** 这是 Python 的一个标准用法。它的意思是：“如果当前这个脚本是被直接运行的（而不是被其他 Python 脚本当作模块导入的），那么就执行下面的代码”。这通常用于程序的入口点。

**`#step1根据图像路径得到所有图像的列表`** 这是一行单行注释（以 `#` 开头）。它不会被程序执行，仅仅是写给程序员看的，用来标记和说明接下来的代码是在做“获取图像列表”的第一步工作。

**`img_dir = r"D:\data\flowers_data\jpg"`** 这一行定义了一个名为 `img_dir` 的变量，用来存储图片所在的文件夹路径。 *注意字符串前面的小写字母 `r`*：它代表“原始字符串（raw string）”。在 Windows 系统中，路径通常使用反斜杠 `\`，而反斜杠在 Python 中默认是转义字符（比如 `\n` 代表换行）。加上 `r` 之后，Python 就会把 `\` 当作普通的斜杠处理，防止路径解析出错。

**`img_list = [os.path.join(img_dir, name) for name in os.listdir(img_dir)]`** 这是一句非常 Pythonic 的“列表推导式”，它把几步操作浓缩在了一行：

1. `os.listdir(img_dir)`：读取 `img_dir` 文件夹里面的所有文件和子文件夹的**名称**（仅仅是名字，比如 `image1.jpg`）。
2. `for name in ...`：遍历这些名称。
3. `os.path.join(img_dir, name)`：将原本的文件夹路径和文件名智能拼接起来，变成完整的文件路径（比如 `D:\data\flowers_data\jpg\image1.jpg`）。
4. 最终，这行代码生成了一个包含所有图片**完整路径**的列表，并把它赋值给变量 `img_list`。

**`random.seed(10086)`** 这行代码用于设置随机数生成器的“种子（seed）”为 `10086`。 在编程中，所谓的“随机”其实是伪随机。如果你设置了一个固定的种子，那么无论你运行这段代码多少次，接下来的随机操作（比如打乱顺序）得出的结果都将是**一模一样**的。这在模型训练时非常关键，可以保证你的实验结果是可复现的。

**`random.shuffle(img_list)`** 这行代码调用 `random` 模块的 `shuffle` 方法，直接对 `img_list` 这个列表进行“洗牌”（就地打乱列表里元素的顺序）。因为上一行设定了固定的种子 `10086`，所以每次运行这行代码时，列表被打乱后的最终顺序都是一致的。

```python
#step2根据比例获得训练集和验证集的列表 8:2
    train_ratio = 0.8
    valid_ratio = 0.2
    num_img = len(img_list)
    num_train = int(num_img * train_ratio)
    num_valid = num_img - num_train
    train_list = img_list[: num_train]
    valid_list = img_list[num_train: ]
```

**`train_ratio = 0.8`** 定义一个名为 `train_ratio` 的变量，将训练集所占的比例设置为 0.8（即 80%）。

**`vaild_ratio = 0.2`** 定义一个名为 `vaild_ratio` 的变量，将验证集所占的比例设置为 0.2（即 20%）。*（温馨提示：这里的单词拼写稍微有一点笔误，正确的拼写通常是 `valid_ratio`，但不影响程序的正常运行，只要后面保持一致即可。）*

**`num_img = len(img_list)`** 调用 Python 内置的 `len()` 函数，计算 `img_list` 里面一共有多少张图片的路径。这个总数被赋值给变量 `num_img`。

**`num_train = int(num_img \* train_ratio)`** 这行代码计算训练集应该包含多少张图片：

1. 先将图片总数乘以 0.8（`num_img * train_ratio`）。
2. 因为乘法得到的结果可能是一个带有小数的浮点数（比如总数是 101，乘出来是 80.8），而图片的数量必须是整数。所以这里使用了 **`int()`** 函数来进行向下取整，确保得到的 `num_train` 是一个整数。

**`num_valid = num_img - num_train`** 这行代码计算验证集应该包含多少张图片。它非常聪明地使用了**总数减去训练集数量**的方式，而不是使用 `int(num_img * vaild_ratio)`。这样做可以完美避免因为前面取整而导致的四舍五入误差，确保（训练集图片数 + 验证集图片数）绝对等于总图片数，没有任何遗漏。

**`train_list = img_list[: num_train]`** 这里使用了 Python 中非常强大的**列表切片（Slicing）**功能。`[: num_train]` 的意思是：从列表的最开始（索引 0）一直截取到索引为 `num_train` 的位置（**不包含** `num_train` 本身）。截取出来的这一大段列表被保存为 `train_list`，也就是我们的训练集。

**`valid_list = img_list[num_train: ]`** 同样是列表切片。`[num_train: ]` 的意思是：从索引 `num_train` 的位置开始，一直截取到列表的最后。因为前一步的截取刚好在 `num_train` 之前停下，所以这一步完美地接上了剩下的所有图片路径。截取出来的这一段被保存为 `valid_list`，即验证集。

```python
#step3根据列表把图像移动到新的文件夹下

    target_dir = os.path.abspath(os.path.dirname(img_dir))

    copy_file(train_list,target_dir,"train")

    copy_file(valid_list,target_dir,"valid")

def copy_file(img_list, target_dir, setname='train'):

    img_dir = os.path.join(target_dir,setname)

    os.makedirs(img_dir, exist_ok = True)

    for p in img_list:

        shutil.copy(p,img_dir)

    print(f"{setname} dataset: copy {len(img_list)} images to {img_dir}")
```

 核心功能函数 `copy_file`

这段代码定义了一个专门用来复制文件的“小工具”。

- **`def copy_file(img_list, target_dir, setname='train'):`** 定义了一个名为 `copy_file` 的函数。它接收三个参数：
  1. `img_list`：要处理的图片路径列表（比如前面生成的 `train_list` 或 `valid_list`）。
  2. `target_dir`：目标存放的总目录。
  3. `setname='train'`：子文件夹的名字。这里给了一个默认值 `'train'`，如果你调用函数时不写第三个参数，它就默认是 'train'。
- **`img_dir = os.path.join(target_dir,setname)`** 将目标总目录（`target_dir`）和子文件夹名（`setname`）拼接起来，得到最终存放图片的具体文件夹路径。比如拼接成 `D:\data\flowers_data\train`。
- **`os.makedirs(img_dir, exist_ok = True)`** 这是非常实用的一行代码！它的作用是**创建这个文件夹**。 `exist_ok = True` 是一个“护身符”：如果这个文件夹还不存在，它就会新建一个；如果这个文件夹**已经存在了**，程序也不会报错崩溃，而是静悄悄地继续往下执行。
- **`for p in img_list:`** 使用 `for` 循环，挨个遍历列表 `img_list` 里的每一个图片绝对路径，并把当前正在处理的路径暂存到变量 `p` 中。
- **`shutil.copy(p,img_dir)`** 调用 `shutil` 模块的 `copy` 方法，把路径为 `p` 的这张图片，**复制**一份到我们刚刚创建的 `img_dir` 文件夹里。
- **`print(f"{setname} dataset: copy {len(img_list)} images to {img_dir}")`** 任务完成后，打印一条提示信息报告战况。这里用了 Python 的 `f-string` 语法（字符串前面加 `f`），可以很方便地把变量的值塞进字符串里。比如打印出：“train dataset: copy 800 images to D:\data\flowers_data\train”。

# 2026.2.25

## 读取数据集（转换成Tensor）

```python
from torch.utils.data import Dataset
from typing import Any
from PIL import Image
import os
class FlowerDataset(Dataset):
    def __init__(self,img_dir,transform = None) -> None:
        super().__init__()
        self.img_dir = img_dir
        self.img_infos = [] #path,label ...
        self._get_img_info()
        self.transform = transform

    def __getitem__(self,index) -> Any:
        img_info:Dict = self.img_infos[index]
        img_path,label_id = img_info["path"],img_info["label"]
        #PIL优：适配torchvision.transform 劣：边缘端非py部署不支持PIL读取
        img = Image.open(img_path).convert("RGB")
        #opencv cv2
        #img = cv2.imread(img_path) #BGR
        #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
        if self.transform is not None:
            img = self.transform(img)

        return img,label_id
    
    def __len__(self):
        return len(self.img_infos)
    
    def _get_img_info(self):
        """ 根据图片文件夹路径获得所有图片的信息
        """
        label_file = os.path.join(os.path.dirname(self.img_dir),"imagelabels.mat")
        assert os.path.exists(label_file)
        #read .mat
        from scipy.io import loadmat
        #[1,8189] 0-1:label_id 1-2:label_id,...
        label_array = loadmat(label_file)["labels"]
        #min_id:1 max_id:102 1-102 pytorch:0-101
        label_array -= 1 #from 0

        #根据图像名得到对应的label_id
        for img_name in os.listdir(self.img_dir):
            path = os.path.join(self.img_dir,img_name)
            if not img_name[6:11].isdigit():
                continue
            img_id = int(img_name[6:11])
            col_id = img_id - 1
            cls_id = int(label_array[:,col_id])#from 0
            self.img_infos.append({"path":path,"label":cls_id})

if __name__  == "__main__":
    img_dir = r"D:\data\flowers_data\train"
    dataset = FlowerDataset(img_dir)
    img,label_id = dataset[0]
    data_size = len(dataset)

```

### 什么是 .mat 文件？有什么用？

- **它的真身：** `.mat` 是 **MATLAB** 软件专属的数据存储格式。就像 Excel 保存为 `.xlsx`，Word 保存为 `.docx` 一样，MATLAB 把它的矩阵、变量保存为 `.mat`。

- **为什么会出现在这里：** 这个数据集（看名字应该是著名的 Oxford 102 Flowers 数据集）的原始作者，当年习惯使用 MATLAB 来做科研。他们没有用我们常见的 `.txt` 或 `.csv` 来记录“哪张图片对应哪个花卉编号”，而是把这 8000 多张图片的标签，打包成了一个巨大的数组（矩阵），直接存成了 `imagelabels.mat`。

  **在这里的作用：** 它就是一个**“标签字典”**。里面存放着一个数组，数组的第 1 个位置记录着第 1 张图片的类别，第 2 个位置记录着第 2 张图片的类别，以此类推。我们需要用 Python 的 `scipy` 库把它“翻译”读取出来，赋给对应的图片

  ###  深度学习数据预处理与 PyTorch Dataset 核心问题答疑笔记

  ### 一、 Python 基础与语法机制

  **1. `img_list` 到底属于什么变量？**

  - **解答：** 它是一个**由字符串（String）组成的列表（List）**。可以把它想象成一个装满纸条的盒子，每张纸条上写着一张图片的“绝对路径”（如 `'D:\...\image_001.jpg'`）。后续的打乱（`shuffle`）和切片操作都是基于它是一个列表的特性。

  **2. 引入包时，`import xxx` 和 `from xxx import yyy` 有什么区别？为什么不全用 `import`？**

  - **解答：** 两者都会把库加载进内存，区别在于**调用时的写法**。
    - `import torch`：把整个工具箱搬过来，每次用里面的东西都要带上长长的前缀（如 `torch.utils.data.Dataset`），防重名但代码繁琐。
    - `from torch.utils.data import Dataset`：把特定的工具直接拿出来放在桌面上，调用时直接写 `Dataset()` 即可。代码极其清爽，在深度学习框架中非常常用。

  **3. Python 类里面，`def _func()` (单下划线) 和 `def __func()` (双下划线) 的区别？**

  - **解答：** * **单下划线 `_`（君子协定）：** 提示这是类的内部方法，不建议外部直接调用，但 Python 解释器**不会强制阻止**外部访问。
    - **双下划线 `__`（强制机制）：** 触发 Python 的“名称改编（Name Mangling）”机制，Python 会偷偷把这个方法改名（加上类名前缀），主要为了防止子类意外覆盖父类方法。外部直接调用会报错。

  **4. 为什么 `img, label_id = dataset[0]` 可以直接返回并接收两个变量？**

  - **解答：** 这是 Python 的**元组解包（Tuple Unpacking）**机制。当函数 `return a, b` 时，底层会自动打包成一个元组 `(a, b)`。接收时如果等号左边写了两个变量名，Python 会自动把元组拆开并一一对应赋值。

  ------

  ### 二、 PyTorch 数据集设计哲学与机制

  **1. 既然已经用代码把图片按 8:2 分进了 train 和 valid 文件夹，为什么还要写一大串 `FlowerDataset` 类？**

  - **解答：** 神经网络（主厨）只认识“纯数字矩阵（Tensor）”，不认识物理文件夹和 `.jpg` 文件。`FlowerDataset` 相当于一个**备菜员**，它的任务是：去硬盘找到图片 -> 读取图片 -> 转换成数字矩阵 -> 查出对应的数字标签 -> 把矩阵和标签打包递给模型。它是连接“物理硬盘”和“数学模型”的桥梁。

  **2. 深度学习图像分类的总体步骤是什么？**

  - **解答：** 主要分为四大核心阶段：
    1. **数据准备：** 收集图片 -> 划分物理文件夹 -> 写 Dataset 类（备菜员） -> 写 DataLoader（传菜员）。
    2. **模型构建：** 搭建或加载预训练好的神经网络（如 ResNet）。
    3. **训练与验证：** 前向传播猜结果 -> 计算损失（Loss） -> 反向传播算梯度 -> 优化器（Optimizer）更新参数。随后在验证集上评估准确率。
    4. **保存模型：** 保存表现最好的参数权重 `.pth` 文件。

  **3. 代码里经常被调用的 `dataset[0]`，为什么会自动执行 `__getitem__()` 方法？**

  - **解答：** `__getitem__` 是 Python 的**魔法方法（Magic Method）**。中括号 `[]` 只是一个语法糖，当 Python 解释器看到对对象使用中括号取值时，就会在底层自动触发并调用该类的 `__getitem__` 方法，并将中括号里的数字作为 `index` 参数传进去。

  **4. 自定义解析方法 `def _get_img_info(self)` 是在什么时候被执行的？为什么要这么设计？**

  - **解答：** 它是在**实例化对象的那一瞬间（即执行 `dataset = FlowerDataset(...)` 时）**，被 `__init__` 初始化方法自动调用执行的，且**只执行一次**。
    - **设计目的：** 相当于“开店前的备菜”。必须在训练开始前，一次性把所有图片的路径和标签对应好存入内存列表。如果放在 `__getitem__` 里，模型每次看一张图都要重新遍历一遍硬盘，训练速度会慢得无法忍受。

  ------

  ### 三、 数据处理与 NumPy 解析

  **1. 代码里的 `.mat` 文件到底是什么？有什么用？**

  - **解答：** `.mat` 是 MATLAB 软件的数据存储格式。在这个数据集中，原作者将所有图片对应的“类别编号”以矩阵的形式打包存在了这个文件里。它的作用就是一个**“标签字典”**，告诉程序第几号图片属于哪种花。

  **2. 如何理解代码中的矩阵切片 `cls_id = int(label_array[:, col_id])`？**

  - **解答：** 这是 NumPy 多维数组的切片语法 `[行切片, 列切片]`。
    - 逗号左边的 `:` 代表“所有的行”。
    - 逗号右边的 `col_id` 代表“指定的列索引”。
      - 合起来的意思是：“我要提取出这个矩阵所有行中，第 `col_id` 列的数据”							



## train.py

```python
#训练花朵分类模型脚本
import torch
from torchvision import transforms,models
from flower_dataset import FlowerDataset
from torch.utils.data import DataLoader
from torch import nn,optim

if __name__  == "__main__":

#参数配置
    train_dir = "" 
    valid_dir = ""
    batch_size = 64
    max_epoch = 40
    num_cls = 102
    lr0 = 0.01
    momentum = 0.9
    weight_decay = 1e-4
    milestones = [25, 35]
    decay_factor = 0.1
    norm_mean,norm_std = [0.485,0.456,0.406] , [0.229,0.224,0.225]

    #实例化dataset(train valid)
    train_transform = transforms.Compose([
        transforms.Resize(256),#(256,256)区别 256：短边保持256 1920*1080[1080->256 1920*1080/256]
        transforms.RandomCrop(224),#模型最终的输入大小[224,224]
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ToTensor(),#0-225 -> 0-1 float HWC -> CHW -> BCHW
        transforms.Normalize(norm_mean,norm_std)#减去均值 除以方差
    ])
    train_dataset = FlowerDataset(img_dir = train_dir, transform = train_transform)
    #valid
    valid_transform = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize(norm_mean,norm_std)
    ])
    valid_dataset = FlowerDataset(data_dir = valid_dir,transform = valid_transform)
    #组装dataloader
    train_loader = DataLoader(train_dataset, batch_size, shuffle = True,num_workers = 2)
    valid_loader = DataLoader(valid_dataset, batch_size, shuffle = False,num_workers = 2)
    #实例化网络模型
    model = models.resnet18(pretrained = True)
    in_features = model.fc.in_features
    fc = nn.Linear(in_features = in_features,out_features = num_cls)
    model.fc = fc

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device = device) 
    #优化器相关
        #loss函数
    loss_fn = nn.CrossEntropyLoss()
        #优化器实例化
    optimizer = optim.SGD(model.parameters(), lr = lr0,momentum = momentum,weight_decay = weight_decay)
        #lr的下降策略实例化
    lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones = milestones,gamma = decay_factor)

#loop

    for epoch in range(max_epoch):
        """一次epoch的训练
           按batch形式取数据
           前向传播
           计算Loss
           反向传播计算梯度
           更新权重
           统计Loss 准确率
        """
        loss_train,acc_train,conf_mat_train,path_error_train = ModelTrainer.train_one_epoch(
            train_loader,model,
            loss_f = loss_fn,
            optimizer = optimizer,
            scheduler = lr_scheduler,
            epoch_idx = epoch,
            device = device,
            log_interval = log_interval,
            max_epoch = max_epoch,
        )
        """
            一次epoch验证
            按Batch形式取数据
            前向传播
            计算Loss
            统计Loss  准确率
        """
        loss_valid,acc_valid,conf_mat_valid,path_error_valid = ModelTrainer.valid_one_epoch(
            valid_loader,
            model,loss_fn,
            device = device,
        )
        #保存模型
        checkpoint = {
            "model": model.state_dict(),
            "epoch": epoch,
        }
        torch.save(checkpoint,f"{output_dir}/model.pth")
    
```

### 第一部分：准备工作（导入依赖包）

Python

```python
import torch
import time
import os
```

- `import torch`: 导入 PyTorch 深度学习框架的核心大本营。
- `import time`: 导入 Python 的时间模块，一会儿用来获取当天的日期。
- `import os`: 导入操作系统模块，用来创建文件夹和处理文件路径。

Python

```python
from torchvision import transforms,models
from flower_dataset import FlowerDataset
from torch.utils.data import DataLoader
from torch import nn,optim
from model_trainer import ModelTrainer
```

- `from torchvision import transforms, models`: 导入视觉工具箱。`transforms` 是用来切菜洗菜的（图像预处理），`models` 是官方提供的现成菜谱（预训练网络模型）。
- `from flower_dataset import FlowerDataset`: **这是把你上节课写的代码拉进来了！** 告诉程序去旁边那个叫 `flower_dataset.py` 的文件里，把咱们写好的 `FlowerDataset` 类（备菜员）请过来。
- `from torch.utils.data import DataLoader`: 导入 PyTorch 的“传菜员”。
- `from torch import nn, optim`: 导入神经网络积木库 (`nn`) 和优化器库 (`optim`)。
- `from model_trainer import ModelTrainer`: 导入别人（或者你）提前封装好的 `ModelTrainer` 类。这个类里隐藏了具体的“前向传播、算误差、反向传播”的繁琐步骤，让主代码显得非常整洁。

------

### 第二部分：控制台（超参数与路径配置）

Python

```python
if __name__  == "__main__":
    #参数配置
    train_dir = r"D:\data\flowers_data\train"
    valid_dir = r"D:\data\flowers_data\valid"
```

- 程序的入口。定义了你硬盘上训练集和验证集的绝对路径。

Python

```python
    batch_size = 64
    max_epoch = 40
    num_cls = 102
```

- `batch_size = 64`:  设定每次送入主厨（GPU）处理的图片数量。64 张图打包成一个批次（Batch）一起算，速度更快且梯度更稳定。
- `max_epoch = 40`: 模型要把所有的训练图片反反复复看 40 遍。
- `num_cls = 102`: 明确咱们的任务是 102 分类。

Python

```python
    lr0 = 0.01
    momentum = 0.9
    weight_decay = 1e-4
```

- `lr0 = 0.01`: 初始学习率（Learning Rate）。决定了模型早期纠正错误时的步伐有多大。
- `momentum = 0.9`: 动量。让模型在寻找最优解（下坡）时带一点惯性，冲过那些容易卡住的小坑。
- `weight_decay = 1e-4`: 权重衰减（L2正则化）。一种防止模型“死记硬背”（过拟合）的惩罚机制。

Python

```python
    milestones = [25, 35]
    decay_factor = 0.1
    log_interval = 10 #iteration
```

- `milestones = [25, 35]`: 学习率下降的“里程碑”。意思是等训练到第 25 轮和 35 轮时，要采取特殊行动。
- `decay_factor = 0.1`: 到了里程碑，学习率就乘以 0.1。步伐变小，开始进行“微调”。
- `log_interval = 10`: 每训练 10 个 Batch，就在屏幕上打印一次日志（报告一下当前的 Loss 和进度）。

Python

```python
    norm_mean,norm_std = [0.485,0.456,0.406] , [0.229,0.224,0.225]
```

- 这是著名的 ImageNet 数据集的 RGB 三通道均值和标准差。因为我们一会儿要用预训练模型，所以必须按照它的习惯来对图片进行归一化。

Python

```python
    time_str = time.strftime("%Y%m%d")
    output_dir = f"outputs/{time_str}"
    os.makedirs(output_dir,exist_ok = True)
```

- `time.strftime`: 获取今天的日期，格式为“年月日”（比如 "20260226"）。
- `output_dir = ...`: 拼凑出一个输出文件夹路径（比如 `outputs/20260226`）。
- `os.makedirs`: 自动在当前目录下建好这个文件夹，用来存放一会儿训练好的模型。`exist_ok=True` 保证了即使文件夹已经存在，也不会报错。

------

### 第三部分：流水线装配（数据增强与 DataLoader）

Python

```python
    #实例化dataset(train valid)
    train_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.RandomCrop(224),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ToTensor(),
        transforms.Normalize(norm_mean,norm_std)
    ])
    train_dataset = FlowerDataset(img_dir = train_dir, transform = train_transform)
```

- 定义了一套花式切菜法（缩放、随机裁剪到 224x224、50%概率水平翻转、转成张量、归一化），并把它交给了你写的 `FlowerDataset`，造出了专门负责训练数据的“备菜员”。

Python

```python
    #valid
    valid_transform = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize(norm_mean,norm_std)
    ])
    valid_dataset = FlowerDataset(img_dir = valid_dir,transform = valid_transform)
```

- 定义验证集的处理方法。**考试期间严禁花里胡哨**，所以去掉了随机裁剪和翻转，直接 Resize 成 224x224 并转张量。造出专门负责验证数据的“备菜员”。

Python

```python
    #组装dataloader
    train_loader = DataLoader(train_dataset, batch_size, shuffle = True,num_workers = 2)
    valid_loader = DataLoader(valid_dataset, batch_size, shuffle = False,num_workers = 2)
```

- 召唤传菜员！把备菜员装进去，规定每次端 64 盘菜（`batch_size`），开启 2 个子线程搬运（`num_workers = 2`）。
- **关键点：** `train_loader` 的 `shuffle = True` 表示训练时要打乱图片顺序；`valid_loader` 的 `shuffle = False` 因为是考试测准确率，打不打乱无所谓，为了节省算力通常关掉。

------

### 第四部分：搭建模型与制定规则

Python

```python
    #实例化网络模型
    model = models.resnet18(pretrained = True)
```

- 从 PyTorch 官方仓库下载并实例化一个预训练好的 ResNet18 卷积神经网络。它已经具备了识别基础图像特征的能力。

Python

```python
    in_features = model.fc.in_features
    fc = nn.Linear(in_features = in_features,out_features = num_cls)
    model.fc = fc
```

- 因为原版 ResNet18 的全连接层（`model.fc`）输出是 1000 个类别。
- 我们读取了它原本的输入神经元个数（`in_features`），然后自己造了一个新的线性层 `fc`，输出个数改为咱们的 102（`num_cls`）。
- 最后用咱们的新层，把模型原来的最后一层给“替换”掉。这就是**迁移学习的“换头术”**！

Python

```python
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device = device) 
```

- 检测电脑有没有 NVIDIA 显卡并且安装了 CUDA 驱动。有的话 `device` 就是 `"cuda"`，否则降级成 `"cpu"`。
- `model.to(device)`: 将整个庞大的神经网络搬到指定的设备（显卡）显存中准备开工。

Python

```python
    #优化器相关
        #loss函数
    loss_fn = nn.CrossEntropyLoss()
```

- 实例化交叉熵损失函数。这是分类任务的绝对主力，用来评估模型猜的分类结果和真实标签之间的差距有多大。

Python

```python
        #优化器实例化
    optimizer = optim.SGD(model.parameters(), lr = lr0,momentum = momentum,weight_decay = weight_decay)
```

- 实例化随机梯度下降（SGD）优化器。我们把模型里所有的参数（`model.parameters()`）都交给它托管，并告诉它初始学习率、动量和惩罚系数。模型能不能学好，全靠它来微调参数。

Python

```python
        #lr的下降策略实例化
    lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones = milestones,gamma = decay_factor)
```

- 实例化学习率调度器。把它和优化器绑定在一起，设定在第 25 和 35 轮时，强行把优化器的学习率乘以 0.1。

------

### 第五部分：核心引擎（大循环训练）

Python

```python
#loop
    for epoch in range(max_epoch):
```

- 一切准备就绪，开启 40 轮的终极大循环！在这个循环里，模型将不断地看图、犯错、纠正、变强。

Python

```python
        loss_train,acc_train,conf_mat_train,path_error_train = ModelTrainer.train_one_epoch(
            train_loader,model,
            loss_f = loss_fn,
            optimizer = optimizer,
            scheduler = lr_scheduler,
            epoch_idx = epoch,
            device = device,
            log_interval = log_interval,
            max_epoch = max_epoch,
        )
```

- 调用提前写好的 `train_one_epoch` 函数，执行**完整的一轮训练**。

- 你把传菜员、模型、裁判（Loss）、教练（优化器）全部传了进去。它在内部默默地完成了无数次的前向传播和反向传播。

- 运行结束后，它会向你汇报这一轮的平均误差（`loss_train`）、准确率（`acc_train`）、混淆矩阵以及猜错的图片路径。

Python

```python
        loss_valid,acc_valid,conf_mat_valid,path_error_valid = ModelTrainer.valid_one_epoch(
            valid_loader,
            model,loss_fn,
            device = device,
        )
```

- 紧接着，调用 `valid_one_epoch` 函数，在验证集上**进行一次考试**。
- 注意看，这里**没有**传 `optimizer` 进去！因为考试时绝对不能允许模型更新参数（作弊），只能正向看图算准确率。

Python

```python
        #保存模型
        checkpoint = {
            "model": model.state_dict(),
            "epoch": epoch,
        }
        torch.save(checkpoint,f"{output_dir}/model.pth")
```

- 当这一轮训练加考试都结束后，创建一个名为 `checkpoint` 的字典，里面装上了模型目前的权重数据（`state_dict()`）和当前的轮数。

- 使用 `torch.save` 把这个字典存到咱们一开始建好的 `outputs/20260226/model.pth` 文件中。

- *小建议：这样写每次 epoch 都会覆盖保存上一次的模型。工业上通常会加一个 if 判断，比如 `if acc_valid > best_acc:`，只保存在验证集上得分最高的那次模型。*

  
  
  ### 1. 数据增强与预处理 (Transforms) 为什么要这样排兵布阵？
  
  **第一问：为什么要进行 transforms？** 因为神经网络是一个死板的“数学机器”，它有两个强硬的要求：
  
  1. **尺寸必须统一**：它不能一会看 1920x1080 的图，一会看 800x600 的图，它要求所有输入的矩阵大小必须一模一样（通常是 224x224）。
  2. **格式必须是 Tensor**：它不认识 JPG 格式，只认识 0~1 之间的浮点数张量。
  
  **第二问：Train 的组合为什么要这么设计？** 这段组合 `Compose` 的顺序极其讲究，它是一套经典的**数据增强（Data Augmentation）**连招：
  
  - **`Resize(256)` -> `RandomCrop(224)`**：为什么不直接 Resize 到 224？直接缩放容易让模型死记硬背。先放大一点点，再**随机**抠出一块 224x224 的区域。这意味着同一张花朵图片，模型在第一轮看到了左半边，第二轮看到了右半边。这强迫模型学习花的**局部特征**，防止过拟合。
  - **`RandomHorizontalFlip`**：随机水平翻转。花朵向左开和向右开，都是同一种花。这相当于零成本把你的数据集扩大了一倍。
  - **`ToTensor`**：核心转换。把 (H, W, C) 的像素矩阵变成 PyTorch 专用的 (C, H, W) 张量，并且把 0~255 的整数像素值除以 255，压平到 0.0~1.0 之间。
  - **`Normalize`**：标准化。减去 ImageNet 的统计均值，除以标准差。这在数学上能让输入数据的分布“归于零均值”，极大地**加快梯度下降的收敛速度**。
  
  **第三问：为什么 Valid 的组合不一样？** 因为 Valid（验证集）是**期末考试**。 训练时（Train）为了让模型变强，我们会故意给它增加难度（随机抠图、随机翻转）。但在考试时，为了公平、稳定地评估它的真实水平，我们**绝对不能引入随机性**。所以验证集直接老老实实地缩放并转化为 Tensor。
  
  ------
  
  ### 2. 迁移学习：为什么要选 ResNet18？最后一层怎么敢直接换？
  
  **第一问：为什么要使用 ResNet18？** ResNet（残差网络）是计算机视觉的里程碑。ResNet18 层数适中，既有足够强大的特征提取能力，又能在普通显卡上跑得飞快，是做图像分类的“万金油”首选。代码里的 `pretrained=True` 意味着这个网络已经在 ImageNet 的 100 多万张图片上训练过，**它已经懂得了如何提取边缘、纹理、色彩等通用特征。**
  
  **第二问：为什么输入输出关系能直接用 `nn.Linear` 转换？不考虑原来的权重了吗？** 这就是**迁移学习（Transfer Learning）**的精髓所在！
  
  - 你可以把预训练的 ResNet18 想象成一个分成两部分的机器：前面一大堆卷积层是**“眼睛”（特征提取器）**，最后一层全连接层 `model.fc` 是**“嘴巴”（分类器）**。
  - 原版的“嘴巴”是用来喊出 1000 种物品名称的（狗、猫、车等），它的权重矩阵大小是 `[1000, 512]`。
  - 我们的花朵只有 102 种。所以我们**毫不留情地把原版的“嘴巴”拆下来扔掉**（那些预测 1000 类的旧权重不要了）。
  - 我们用 `nn.Linear` 换上了一个新的“嘴巴”（大小为 `[102, 512]`）。**这个新嘴巴的权重是随机初始化的。**
  - **训练的本质：** 依靠预训练的“眼睛”看花朵提取特征，然后重点训练这个新“嘴巴”，让它学会把看到的特征映射到 102 种花朵上。
  
  ------
  
  ### 3. 优化引擎：Loss、SGD 与学习率
  
  **第一问：为什么选交叉熵（CrossEntropyLoss）？** 在多分类问题（102 选 1）中，交叉熵是绝对的王者。它在底层做了两件事：先用 Softmax 把模型的原始输出变成**概率分布**（所有类别概率加起来等于 1），然后计算这个概率分布跟真实标签（100% 属于某类）之间的差距。它极其严厉：模型猜对的概率越低，它给的惩罚（Loss 值）就成指数级暴增。
  
  **第二问：为什么选 SGD（随机梯度下降）？它的参数什么意思？** SGD 就像一个蒙着眼睛下山的人，根据脚底的坡度（梯度）寻找最低谷（Loss 最小的点）。
  
  - `lr=0.01` (Learning Rate)：下山的步子大小。太大容易跨过最低点，太小走得慢。
  - `momentum=0.9` (动量)：如果在下坡，它会积攒速度（惯性）。这能帮助下山的人冲过那些半山腰的“小坑（局部最优解）”，更快冲向谷底。
  - `weight_decay=1e-4` (权重衰减)：数学上的 L2 正则化。它会默默惩罚模型里那些数值过大的权重，逼迫模型学得“平滑一点”，不要死记硬背训练集的特征。
  
  **第三问：学习率调整参数有什么意义？** `milestones=[25, 35], gamma=0.1`。 你可以想象，快走到谷底的时候，如果还迈着大步子（0.01），就会在谷底两边来回横跳，永远踩不到最底部的那个点。所以设定一个策略：训练到第 25 轮和 35 轮时，步子强制缩小到原来的 1/10。这就叫**“粗调转微调”**，能让模型的准确率在最后阶段再往上拔高一截。
  
  ------
  
  ### 4. 终极奥义：模型到底是怎么被保存的？
  
  **第一问：`checkpoint` 创建了个什么东西？** `checkpoint`（检查点）在代码里其实非常朴素——它就是一个**Python 字典（Dictionary）**。 在打游戏时，存档不仅仅要存“主角的属性”，还要存“打到了第几关”。`checkpoint` 也是一样，它打包了两个核心信息：
  
  1. `"model": model.state_dict()` -> 模型的属性。
  2. `"epoch": epoch` -> 当前打到了第几关。 这样万一你训练到 20 轮突然停电了，下次读取这个字典，就能从第 20 轮接着往下练，不用从头再来。
  
  **第二问：训练出来的模型到底是怎么被表示的？** 调用 `model.state_dict()` 时，并没有保存模型的一行行代码（比如 `transforms` 是什么、有多少层卷积），它保存的**纯粹是一堆数字矩阵（Tensors）**。 它在内存里大概长这样：
  
  Python
  
  ```python
  {
     'conv1.weight': tensor([[[ 0.1, -0.2...], ...]]),  # 第一层卷积的权重数字
     'layer1.0.bn1.bias': tensor([1.2, 0.4, ...]),      # 归一化层的偏置数字
     'fc.weight': tensor([[-0.5, 0.8...], ...])         # 最后全连接层的数字
  }
  ```
  
  `torch.save` 会把这个庞大的字典序列化，压缩成一个二进制文件（`model.pth`）写进硬盘。当你以后想要**部署预测**的时候，你需要先用代码重新搭起一个一模一样的“空壳” ResNet18，然后把这个 `.pth` 文件里的数字原封不动地填进对应的层里，模型就“复活”了！

# 2026.2.26

## model_trainer.py

```python
import torch
import numpy as np
from collections import Counter


class ModelTrainer:

    @staticmethod
    def train_one_epoch(data_loader,model,loss_f,optimizer,scheduler,epoch_idx,device,log_interval,max_epoch):
        model.train()

        num_cls = model.fc.out_features
        conf_mat = np.zeros((num_cls,num_cls))
        loss_sigma = []
        loss_mean = 0
        acc_avg = 0
        path_error = []
        for i, data in enumerate(data_loader):

            inputs,labels = data
            inputs,labels = inputs.to(device),labels.to(device)

            outputs = model(inputs)
            loss = loss_f(outputs.cpu(),labels.cpu())
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            #统计Loss
            loss_sigma.append(loss.item())
            loss_mean = np.mean(loss_sigma)

            #统计混淆矩阵
            _, predicted = torch.max(outputs.data, 1)
            for j in range(len(labels)):
                cate_i = labels[j].cpu().numpy()
                pred_i = predicted[j].cpu().numpy()
                conf_mat[cate_i,pred_i] += 1.
            acc_avg = conf_mat.trace() / conf_mat.sum()

            #每10个iteration 打印一次训练信息
            if i % log_interval == log_interval - 1:
                print("Training:Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss:{:.4f} Acc:{:.2%}".
                            format(epoch_idx + 1,max_epoch,i + 1,len(data_loader),loss_mean,acc_avg))
        #print("epoch:{} sampler:{}".format(epoch_idx,Counter(label_list)))
        return loss_mean,acc_avg,conf_mat,path_error
    

    @staticmethod
    def valid_one_epoch(data_loader,model,loss_f,device):
        model.eval()

        num_cls = model.fc.out_features
        conf_mat = np.zeros((num_cls,num_cls))
        loss_sigma = []
        path_error = []

        for i, data in enumerate(data_loader):
            #inputs,labels,path_imgs = data
            inputs, labels = data
            inputs, labels = inputs.to(device),labels.to(device)

            with torch.no_grad():
                outputs = model(inputs)
            loss = loss_f(outputs.cpu(),labels.cpu())

            _, predicted = torch.max(outputs.data, 1)
            for j in range(len(labels)):
                cate_i = labels[j].cpu().numpy()
                pred_i = predicted[j].cpu().numpy()
                conf_mat[cate_i, pred_i] += 1.
            #统计loss
            loss_sigma.append(loss.item())
        acc_avg = conf_mat.trace() / conf_mat.sum()

        return np.mean(loss_sigma), acc_avg, conf_mat, path_error
```

### 一、 头部导入与类定义

Python

```
import torch
import numpy as np
from collections import Counter
```

- `import torch`: 导入 PyTorch 核心库。
- `import numpy as np`: 导入科学计算库 NumPy。我们一会儿要用它来创建和计算“混淆矩阵”。
- `from collections import Counter`: 导入计数器工具。（**小提示**：这行代码导入了但下面被注释掉了没用到，纯属多余，可以删掉）。

Python

```
class ModelTrainer:
```

- 定义一个名为 `ModelTrainer` 的类，把训练和验证的逻辑封装在一起，让主代码显得清爽。

------

### 二、 核心训练逻辑 `train_one_epoch`

Python

```
    @staticmethod
```

- 这是一个 Python 装饰器，表示下面的函数是一个**“静态方法”**。意思是：你不需要先实例化对象（不需要写 `trainer = ModelTrainer()`），可以直接用 `ModelTrainer.train_one_epoch(...)` 来调用它。

Python

```
    def train_one_epoch(data_loader,model,loss_f,optimizer,scheduler,epoch_idx,device,log_interval,max_epoch):
```

- 定义了执行“一轮训练（1 Epoch）”所需的全部要素：传菜员、主厨、裁判、教练等。
- （**小提示**：你把 `scheduler` 传进来了，但在这个函数内部**并没有使用它**。通常 `scheduler.step()` 是写在外层主循环里的，所以这个参数传进来是个摆设，但不影响运行。）

Python

```
        model.train()
```

- **极其关键的一步！** 这行代码向模型下达指令：“现在是训练模式！” 模型内部的某些特殊层（比如 Dropout、BatchNorm）听到指令后，就会开启随机丢弃神经元和更新统计均值等训练专属功能。

Python

```
        num_cls = model.fc.out_features
        conf_mat = np.zeros((num_cls,num_cls))
```

- `num_cls`: 聪明地从模型最后一层（全连接层 `fc`）读取输出的特征数量（即咱们的 102 种花）。
- `conf_mat`: 用 NumPy 创建一个 102 行 102 列的全 0 矩阵，这就是**混淆矩阵**。它用来记录“真实类别是 A，模型却猜成了 B”的次数。

Python

```
        loss_sigma = []
        loss_mean = 0
        acc_avg = 0
        path_error = []
```

- 初始化一堆记分牌：`loss_sigma` 用来装每批次的 Loss 值；`loss_mean` 算平均 Loss；`acc_avg` 算平均准确率；`path_error` 准备记录认错的图片路径（虽然这段代码里没实际往里写）。

Python

```
        for i, data in enumerate(data_loader):
```

- **引擎点火，开始流水线作业！** `enumerate` 会给送过来的每一批数据打上编号 `i`（从 0 开始），`data` 就是传菜员端过来的那批菜。

Python

```
            inputs,labels = data
            inputs,labels = inputs.to(device),labels.to(device)
```

- 解包：把 `data` 拆成图片矩阵 `inputs` 和真实答案 `labels`。
- `.to(device)`: 把图片和答案**搬运到显卡（GPU）的显存里**。主厨在 GPU 里，菜也必须端到 GPU 里才能炒。

Python

```
            outputs = model(inputs)
```

- **前向传播（Forward）！** 把这 64 张图片（inputs）喂给模型，模型吐出 64 份预测结果（outputs）。

Python

```
            loss = loss_f(outputs.cpu(),labels.cpu())
```

- **计算误差！** 让裁判（损失函数 `loss_f`）对比模型的猜测和标准答案，算出罚分 `loss`。
- （**⚠️ 性能瑕疵指出**：你在这里用了 `.cpu()` 把结果搬回内存算 Loss。其实 PyTorch 的 Loss 函数完全可以在 GPU 上算。来回搬运数据会严重拖慢训练速度。建议直接改成 `loss = loss_f(outputs, labels)`）。

Python

```
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
```

- **深度学习的核心三连击（必须死记硬背）！**
  1. `optimizer.zero_grad()`: 清空上一批次残留的梯度（不然梯度会累加，越算越错）。
  2. `loss.backward()`: **反向传播！** PyTorch 在底层疯狂进行微积分链式求导，算出每一个神经元对刚才的错误负多少责任（梯度）。
  3. `optimizer.step()`: 教练（优化器）根据算出来的责任报告（梯度），微调模型里的每一个权重参数。

Python

```
            #统计Loss
            loss_sigma.append(loss.item())
            loss_mean = np.mean(loss_sigma)
```

- `loss.item()`: 把包含梯度的复杂 PyTorch 张量变成一个纯 Python 的小数，塞进列表里。
- 算出截止到当前批次，这轮训练的平均 Loss。

Python

```
            #统计混淆矩阵
            _, predicted = torch.max(outputs.data, 1)
```

- `outputs` 其实是模型给出的 102 个类别的概率打分。`torch.max(..., 1)` 意味着在类别维度（维度 1）找最高分。
- 它返回两个值：最高分是多少（不需要，用 `_` 占位），以及**最高分对应的类别索引（这就是模型的最终预测结果 `predicted`）**。

Python

```
            for j in range(len(labels)):
                cate_i = labels[j].cpu().numpy()
                pred_i = predicted[j].cpu().numpy()
                conf_mat[cate_i,pred_i] += 1.
```

- 遍历这一批次的 64 张图。
- `cate_i` 是真实答案，`pred_i` 是模型猜的答案。
- 在混淆矩阵的第 `cate_i` 行、第 `pred_i` 列加 1。如果猜对了，就会加在矩阵的对角线上。

Python

```
            acc_avg = conf_mat.trace() / conf_mat.sum()
```

- **非常优雅的数学计算！** * `conf_mat.trace()`：求矩阵对角线元素之和（也就是**所有猜对的次数**）。
  - `conf_mat.sum()`：求矩阵所有元素之和（也就是**看过的图片总数**）。
  - 两者相除，瞬间得到当前的平均准确率！

Python

```
            #每10个iteration 打印一次训练信息
            if i % log_interval == log_interval - 1:
                print("Training:Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss:{:.4f} Acc:{:.2%}".
                            format(epoch_idx + 1,max_epoch,i + 1,len(data_loader),loss_mean,acc_avg))
```

- 为了防止盯着黑屏发呆，每隔 10 个批次，就在屏幕上打印一次当前的轮数、批次、Loss 和准确率。

Python

```
        return loss_mean,acc_avg,conf_mat,path_error
```

- 当所有的图片都过了一遍（循环结束），把这一轮的最终成绩单打包返回给主程序。

------

### 三、 核心验证逻辑 `valid_one_epoch`

验证代码和训练代码有 80% 是重复的，我重点讲**三处根本性的不同**：

Python

```
    @staticmethod
    def valid_one_epoch(data_loader,model,loss_f,device):
        model.eval()
```

- **不同点一：下达“考试”指令！** `model.eval()` 告诉模型进入评估模式。此时模型会关闭 Dropout 等随机因素，确保用它最稳健的绝对实力来参加考试。

*(中间的初始化、取数据、搬运到 GPU 步骤与训练完全相同，略)*

Python

```
            with torch.no_grad():
                outputs = model(inputs)
```

- **不同点二：关闭梯度追踪！** `with torch.no_grad():` 是一个上下文管理器。它告诉 PyTorch：“接下来我只做正向计算，**绝对不需要求导算梯度**，你不用帮我记录那些复杂的求导图了。”
- 这不仅能让考试速度起飞，还能省下极其巨大的显存。

Python

```
            loss = loss_f(outputs.cpu(),labels.cpu())
            # ...(计算预测结果、填写混淆矩阵，同上)
            loss_sigma.append(loss.item())
        acc_avg = conf_mat.trace() / conf_mat.sum()

        return np.mean(loss_sigma), acc_avg, conf_mat, path_error
```

- **不同点三：绝对没有 `optimizer.step()`！** 因为是在验证集上考试，我们仅仅计算 Loss 和记录准确率，**严禁模型更新权重（这属于偷看考试答案）**。所以你在这段代码里看不到优化器更新的代码。

## 模型评价指标

### 正确率 召回率 精确率 混淆矩阵

Accuracy：衡量模型在整个数据集上分类正确的比例

Recall：该类样本中，找回了多少。与之对应的是漏检率

Precision：预测为该类的样本中，正确的有多少。与之对应的是误检率

Confusion Matrix：常用来观察分类结果，其是一个N*N的方阵，N代表类别数。

行表示每个类别真实数量，列表示每个类别预测数量。

行用于计算召回率，列用于计算精确度。

混淆矩阵可以帮助分析模型分类偏好

## 模型选择

模型应当选择泛化性能好的，即低方差，同时偏差也要小

误差可分解为：偏差、方差和噪声之和。

偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力

方差度量了同样大小的训练集变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响

噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界

# 2026.2.27

## coding

```python
#通过训练好的模型预测图片
import torch
import os
from PIL import Image
from torchvision import models,transforms
from easydict import EasyDict
from torch import nn


if __name__ == "__main__":
    #初始化模型
    norm_mean,norm_std = [0.485,0.456,0.406] , [0.229,0.224,0.225]

    cfg = EasyDict()
    cfg.num_cls = 102
    cfg.transforms = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize(norm_mean,norm_std)
    ])

    model = models.resnet18(pretrained = True)
    in_features = model.fc.in_features
    fc = nn.Linear(in_features = in_features,out_features = cfg.num_cls)
    model.fc = fc
    #载入训练好的权重
    model_weights = r"outputs\20260226\model.pth"
    checkpoint = torch.load(model_weights)
    model.load_state_dict(checkpoint["model"])


    #读图-预处理
    data_dir = r"D:\data\flowers_data\valid"
    for img_name in os.list(data_dir):

        img_path = os.path.join(data_dir, img_name)
        img0 = Image.open(img_path).convert("RGB")
            
        img:torch.Tensor = cfg.transforms(img0)

        img = img.unsqueeze(dim=0)

        #推理
        device = torch.device("cuda")
        model.to(device= device)

        model.eval()
        img = img.to(device = device)
        with torch.no_grad():
            output = model(img) #1*102

        _,pred_label = torch.max(output,1)

    #展示
    print(f"path: {img_path},pred label:{int(pred_label)}")

```

## AIprompt

### 第一部分：项目深度复盘（梳理你的“工作量”）

**目的：** 让 AI 帮你总结项目的技术亮点，确保你能有条理地陈述做了什么。

> **提示词模板：**
> “我正在准备研究生复试，我的项目是[项目名称，如：基于残差网络的工业缺陷检测分类]。我的技术栈是[如：PyTorch + ResNet50]。请从专业角度帮我梳理这个项目的核心逻辑，并生成一个简洁的**项目介绍（300字以内）**。
> 要求包含：
>
> 1. 
> 2. 这个项目解决了什么痛点？
> 3. 我在数据预处理阶段做了哪些优化（如：数据增强、平衡样本）？
> 4. 模型选择的依据是什么？
> 5. 最终达到的核心指标（Accuracy, F1-score等）及其意义。”

### 第二部分：核心原理“追魂二十问”（应对导师的基础考察）

**目的：** 导师喜欢问“为什么”。AI 可以帮你预演这些深层原理。

> **提示词模板：**
> “针对我的[图像分类项目]，导师可能会问一些深层理论问题。请扮演一位严厉的面试官，针对以下知识点给我列出 5-8 个可能的问题，并给出**高水平的回答要点**：
>
> 1. 
> 2. 为什么选择 [如：ResNet] 而不是 [如：VGG 或 Vision Transformer]？
> 3. 损失函数 [如：CrossEntropy] 的原理及在该场景下的表现？
> 4. 如果模型出现了过拟合，在这个项目中我应该优先尝试哪些方案？
> 5. 谈谈卷积层、池化层和全连接层在图像特征提取中各自扮演的角色。”

------



### 第三部分：理解导师的核心需求（对齐科研思维）

**目的：** 了解导师在看图像分类项目时，真正看重的“学术潜质”在哪里。

> **提示词模板：**
> “在研究生复试中，如果一名导师研究方向是[填入导师的研究方向，如：医疗影像分析/嵌入式视觉/模型压缩]，他会对我的[通用图像分类项目]产生哪些特定的兴趣点？
> 请帮我分析：
>
> 1. 
> 2. 他最看重这个项目中的哪个环节（是算法创新、数据质量还是推理速度）？
> 3. 我应该如何修改我的项目描述，才能更好地契合该导师的研究兴趣？
> 4. 如果他问到‘你觉得这个模型如何落地或改进’，我该从哪个学术前沿角度回答？”

------



### 第四部分：前沿拓展与对比（展现你的视野）

**目的：** 证明你不仅仅会调包，还关注行业动态。

> **提示词模板：**
> “我的项目使用的是传统的 CNN 架构。请帮我总结一下目前图像分类领域的最新趋势（如：MAE, Swin Transformer, 大模型微调等），并告诉我：
>
> 1. 
> 2. 相比于我的项目，这些新技术解决了什么问题？
> 3. 如果我要将项目中的 CNN 替换为 Transformer，我会遇到哪些挑战（如数据量、算力）？
> 4. 如何在面试中优雅地表达‘虽然我用的是基础模型，但我对前沿技术有深入思考’？”
