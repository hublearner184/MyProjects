# 2026.2.8

## Brief History of Visual Object Detection 

1996年SVM(Support Vector Machine),2012年提出AlexNet，后来RCNN,fast-RCNN,faster-RCNN，再到2020年transform，2023年SAM(Segment Anything Model)

## Q & A

### 本节中定义了形状$(2,3,4)$​的张量`X`。`len(X)`的输出结果是什么？对于任意形状的张量`X`,`len(X)`是否总是对应于`X`特定轴的长度?这个轴是什么?

1. `len(X)` 的输出结果与含义

**问题：** 定义形状为 $(2, 3, 4)$ 的张量 `X`，`len(X)` 输出什么？它对应哪个轴？

**答案：**

- **输出结果**：`2`
- **对应轴**：总是对应 **轴 0 (axis 0)**，也就是最外层的维度。

### 运行`A/A.sum(axis=1)`，看看会发生什么。请分析一下原因？

![image-20260208011133410](./2026.2.8.assets/image-20260208011133410.png)

假设 `A` 是一个二维张量，形状为 $(5, 4)$。

1. **求和操作**：`A.sum(axis=1)` 会沿着轴 1（列）将元素相加，从而消掉轴 1。

   - 输入形状：$(5, 4)$
   - 输出形状：$(5,)$ （注意：这里维度变成了一维向量）

2. **除法操作**：试图计算 `(5, 4)` 除以 `(5,)`。

3. **广播失败**：

   PyTorch/NumPy 的广播规则是从**最右边的维度**开始对齐的：

   - `A`:      $(5, \mathbf{4})$
   - `Sum`:    $(~, \mathbf{5})$
   - **冲突**：右侧维度的 `4` 和 `5` 不相等，且都不为 1，因此无法广播，导致报错。

**如何修正？**

需要保持维度（Keepdims），让求和后的结果变成 $(5, 1)$，这样 $(5, 4)$ 和 $(5, 1)$ 就可以成功广播了。

广播规则规定：两个维度兼容，当且仅当它们**相等**，或者**其中一个是 1**。

### 考虑一个具有形状$(2,3,4)$​的张量，在轴0、1、2上的求和输出是什么形状?

求和操作（如果不使用 `keepdims=True`）会**移除**指定的维度。

- **轴 0 (axis=0)**：消除第 1 个维度 $(2)$。
  - 输出形状：$(3, 4)$
- **轴 1 (axis=1)**：消除第 2 个维度 $(3)$。
  - 输出形状：$(2, 4)$
- **轴 2 (axis=2)**：消除第 3 个维度 $(4)$。
  - 输出形状：$(2, 3)$

**直观记忆法：** 输入形状是 $(d_0, d_1, d_2)$，如果你对 $d_i$ 求和，结果形状里就把 $d_i$ 删掉，剩下的拼起来。

### 为`linalg.norm`函数提供3个或更多轴的张量，并观察其输出。对于任意形状的张量这个函数计算得到什么?

对于任意形状的张量（无论是 3D、4D 还是更高维），如果不指定 `dim`（轴）参数，`torch.linalg.norm` 默认计算的是**弗罗贝尼乌斯范数 (Frobenius Norm)**，也就是整个张量中**所有元素的平方和的平方根**。

其输出总是一个**标量 (Scalar)**，即形状为 `torch.Size([])` 的 0 维张量。

## 梯度

我们可以连结一个多元函数对其所有变量的偏导数，以得到该函数的*梯度*（gradient）向量。
具体而言，设函数$f:\mathbb{R}^n\rightarrow\mathbb{R}$的输入是
一个$n$维向量$\mathbf{x}=[x_1,x_2,\ldots,x_n]^\top$，并且输出是一个标量。
函数$f(\mathbf{x})$相对于$\mathbf{x}$的梯度是一个包含$n$个偏导数的向量:

$$\nabla_{\mathbf{x}} f(\mathbf{x}) = \bigg[\frac{\partial f(\mathbf{x})}{\partial x_1}, \frac{\partial f(\mathbf{x})}{\partial x_2}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_n}\bigg]^\top,$$

其中$\nabla_{\mathbf{x}} f(\mathbf{x})$通常在没有歧义时被$\nabla f(\mathbf{x})$取代。

假设$\mathbf{x}$为$n$维向量，在微分多元函数时经常使用以下规则:

* 对于所有$\mathbf{A} \in \mathbb{R}^{m \times n}$，都有$\nabla_{\mathbf{x}} \mathbf{A} \mathbf{x} = \mathbf{A}^\top$
* 对于所有$\mathbf{A} \in \mathbb{R}^{n \times m}$，都有$\nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{A}  = \mathbf{A}$
* 对于所有$\mathbf{A} \in \mathbb{R}^{n \times n}$，都有$\nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{A} \mathbf{x}  = (\mathbf{A} + \mathbf{A}^\top)\mathbf{x}$
* $\nabla_{\mathbf{x}} \|\mathbf{x} \|^2 = \nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{x} = 2\mathbf{x}$

同样，对于任何矩阵$\mathbf{X}$，都有$\nabla_{\mathbf{X}} \|\mathbf{X} \|_F^2 = 2\mathbf{X}$。
正如我们之后将看到的，梯度对于设计深度学习中的优化算法有很大用处。

## 自动微分(autograd)

深度学习框架通过自动计算导数，即（automatic differentiation）来加快求导。实际中，根据设计好的模型，系统会构建一个计算图，来跟踪计算是哪些数据通过哪些操作组合起来产生输出。自动微分使系统能够随后反向传播梯度

## 机器学习那些事

### 数据

如果没有数据，那么数据科学将无用武之地。每个数据集由一个个样本组成，大多时候，它们遵循独立同分布。通常每个样本由一组特征（features）的属性组成。机器学习模型会根据这些属性进行预测。在监督学习问题中，要预测的是一个属性，它被称为标签（label）或目标（target）。

当每个样本的特征类别数量都是一样的时候，其特征向量是固定长度的，这个长度被称为数据的维数。它可以用来量化学习大量样本。

然而不是所有的数据都可以用“固定长度”的向量表示。

以图像数据为例，如果它们全部来自标准显微镜设备，那么“固定长度”是可取的；

但是如果图像数据来自互联网，它们很难具有相同的分辨率或形状。

这时，将图像裁剪成标准尺寸是一种方法，但这种办法很局限，有丢失信息的风险。

此外，文本数据更不符合“固定长度”的要求。

比如，对于亚马逊等电子商务网站上的客户评论，有些文本数据很简短（比如“好极了”），有些则长篇大论。

与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据。

光有海量的数据是不够的，我们还需要正确的数据。如果数据中充满了错误，就成了Garbage in Garbage out。

### 模型

大多数机器学习会涉及到数据的转换。比如一个“摄取照片并预测笑脸”的系统。虽然简单的模型能够解决如上简单的问题，但深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由错综复杂的神经网络交织在一起，包含层层数据转换，因此被称为深度学习（deep learning）。

### 目标函数

在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况下是可优化的，这被称之为目标函数（objective function）。我们通常定义一个目标函数，并希望优化它到最低点。因为越低越好，所以这些函数有时候被称为损失函数（loss function，或cost function）。但这只是一个惯例，我们也可以取一个新的函数，优化到它的最高点，这两个函数本质上是相同的，只是翻转一下符号。

当任务在试图预测数值时，最常见的损失函数是平方误差（squared error），即预测值与实际值之间差的平方。当试图解决分类问题时，最常见的目标函数是最小化错误率，即预测与实际情况不符合的样本比例。

通常损失函数是根据模型参数定义的，并取决于数据集。在一个数据集上，我们可以通过最小化总损失来学习模型参数的最佳值。该数据集由一些为训练而收集的样本组成，称为训练数据集，或者称训练集（training set）。然而，在训练集上表现良好的模型，并不一定在“新数据集”上有同样的性能，这里的“新数据集”通常称为测试集（test set）。

### 优化算法

当我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。在深度学习中，大多流行的优化算法通常基于一种基本方法--梯度下降法（gradient descent）。简而言之，梯度下降法在每个步骤中都会检查参数，看看如果仅对该参数进行少量变动，训练集损失会朝着哪个方向移动。然后，它在可以减少损失的方向上优化参数。

### 监督学习（supervised learning）

擅长在“给定输入特征”的情况下预测标签。每个“特征-标签”对都称为一个样本。有时，即使标签是未知的，样本也可以指代输入特征。我们的目标是生成一个模型，能够将任何输入特征映射到标签（即预测）

监督学习的学习过程一般可以分为三大步骤：

1. 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签（例如，患者是否在下一年内康复？）；有时，这些样本可能需要被人工标记（例如，图像分类）。这些输入和相应的标签一起构成了训练数据集；
2. 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；
3. 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测。

### 回归（regression）

**回归**（regression）是最简单的监督学习任务之一。

假设有一组房屋销售数据表格，其中每行对应一个房子，每列对应一个相关的属性，例如房屋的面积、卧室的数量、浴室的数量以及到镇中心的步行距离，等等。

每一行的属性构成了一个房子样本的特征向量。

如果一个人住在纽约或旧金山，而且他不是亚马逊、谷歌、微软或Facebook的首席执行官，那么他家的特征向量（房屋面积，卧室数量，浴室数量，步行距离）可能类似于：$[600, 1, 1, 60]$。

如果一个人住在匹兹堡，这个特征向量可能更接近$[3000, 4, 3, 10]$......

当人们在市场上寻找新房子时，可能需要估计一栋房子的公平市场价值。

为什么这个任务可以归类为回归问题呢？本质上是输出决定的。

销售价格（即标签）是一个数值。

当标签取任意数值时，我们称之为**回归**问题，此时的目标是生成一个模型，使它的预测非常接近实际标签

### 分类（classification）

虽然回归模型可以很好地解决“有多少”的问题，但是很多问题并非如此。

例如，一家银行希望在其移动应用程序中添加支票扫描功能。

具体地说，这款应用程序能够自动理解从图像中看到的文本，并将手写字符映射到对应的已知字符之上。

这种“哪一个”的问题叫做**分类**（classification）问题。

**分类**问题希望模型能够预测样本属于哪个**类别**（category，正式称为**类**（class））。

例如，手写数字可能有10类，标签被设置为数字0～9。

最简单的分类问题是只有两类，这被称之为**二项分类**（binomial classification）。

例如，数据集可能由动物图像组成，标签可能是$\mathrm{\{猫, 狗\}}$两类。

回归是训练一个回归函数来输出一个数值；

分类是训练一个分类器来输出预测的类别。

### 标记问题

有些分类问题很适合于二项分类或多项分类。

例如，我们可以训练一个普通的二项分类器来区分猫和狗。

运用最前沿的计算机视觉的算法，这个模型可以很轻松地被训练。

尽管如此，无论模型有多精确，当分类器遇到新的动物时可能会束手无策。

比如 :numref:*`fig_stackedanimals`*所示的这张“不来梅的城市音乐家”的图像 （这是一个流行的德国童话故事），图中有一只猫、一只公鸡、一只狗、一头驴，背景是一些树。

取决于我们最终想用模型做什么，将其视为二项分类问题可能没有多大意义。

取而代之，我们可能想让模型描绘输入图像的内容，一只猫、一只公鸡、一只狗，还有一头驴。

学习预测不相互排斥的类别的问题称为**多标签分类**（multi-label classification）。

举个例子，人们在技术博客上贴的标签，比如“机器学习”“技术”“小工具”“编程语言”“Linux”“云计算”“AWS”。

一篇典型的文章可能会用5～10个标签，因为这些概念是相互关联的。

关于“云计算”的帖子可能会提到“AWS”，而关于“机器学习”的帖子也可能涉及“编程语言”。

### 搜索

有时，我们不仅仅希望输出一个类别或一个实值。

在信息检索领域，我们希望对一组项目进行排序。

以网络搜索为例，目标不是简单的“查询（query）-网页（page）”分类，而是在海量搜索结果中找到用户最需要的那部分。

搜索结果的排序也十分重要，学习算法需要输出有序的元素子集。

换句话说，如果要求我们输出字母表中的前5个字母，返回“A、B、C、D、E”和“C、A、B、E、D”是不同的。

即使结果集是相同的，集内的顺序有时却很重要。、

该问题的一种可能的解决方案：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。[PageRank](*https://en.wikipedia.org/wiki/PageRank*)，谷歌搜索引擎背后最初的秘密武器就是这种评分系统的早期例子，但它的奇特之处在于它不依赖于实际的查询。

在这里，他们依靠一个简单的相关性过滤来识别一组相关条目，然后根据PageRank对包含查询条件的结果进行排序。

如今，搜索引擎使用机器学习和用户行为模型来获取网页相关性得分，很多学术会议也致力于这一主题。

### 推荐系统

另一类与搜索和排名相关的问题是**推荐系统**（recommender system），它的目标是向特定用户进行“个性化”推荐。

例如，对于电影推荐，科幻迷和喜剧爱好者的推荐结果页面可能会有很大不同。

类似的应用也会出现在零售产品、音乐和新闻推荐等等。

### 序列学习

以上大多数问题都具有固定大小的输入和产生固定大小的输出。

例如，在预测房价的问题中，我们考虑从一组固定的特征：房屋面积、卧室数量、浴室数量、步行到市中心的时间；

图像分类问题中，输入为固定尺寸的图像，输出则为固定数量（有关每一个类别）的预测概率；

在这些情况下，模型只会将输入作为生成输出的“原料”，而不会“记住”输入的具体内容。

如果输入的样本之间没有任何关系，以上模型可能完美无缺。

但是如果输入是连续的，模型可能就需要拥有“记忆”功能。

比如，我们该如何处理视频片段呢？

在这种情况下，每个视频片段可能由不同数量的帧组成。

通过前一帧的图像，我们可能对后一帧中发生的事情更有把握。

语言也是如此，机器翻译的输入和输出都为文字序列。

再比如，在医学上序列输入和输出就更为重要。

设想一下，假设一个模型被用来监控重症监护病人，如果他们在未来24小时内死亡的风险超过某个阈值，这个模型就会发出警报。

我们绝不希望抛弃过去每小时有关病人病史的所有信息，而仅根据最近的测量结果做出预测。

这些问题是序列学习的实例，是机器学习最令人兴奋的应用之一。

序列学习需要摄取输入序列或预测输出序列，或两者兼而有之。

具体来说，输入和输出都是可变长度的序列，例如机器翻译和从语音中转录文本。

虽然不可能考虑所有类型的序列转换，但以下特殊情况值得一提。

### 无监督学习

到目前为止，所有的例子都与监督学习有关，即需要向模型提供巨大数据集：每个样本包含特征和相应标签值。
打趣一下，“监督学习”模型像一个打工仔，有一份极其专业的工作和一位极其平庸的老板。
老板站在身后，准确地告诉模型在每种情况下应该做什么，直到模型学会从情况到行动的映射。
取悦这位老板很容易，只需尽快识别出模式并模仿他们的行为即可。

相反，如果工作没有十分具体的目标，就需要“自发”地去学习了。
比如，老板可能会给我们一大堆数据，然后要求用它做一些数据科学研究，却没有对结果有要求。
这类数据中不含有“目标”的机器学习问题通常被为*无监督学习*（unsupervised learning），
本书后面的章节将讨论无监督学习技术。
那么无监督学习可以回答什么样的问题呢？来看看下面的例子。

* *聚类*（clustering）问题：没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的网页浏览记录，我们能否将具有相似行为的用户聚类呢？
* *主成分分析*（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。再比如，裁缝们已经开发出了一小部分参数，这些参数相当准确地描述了人体的形状，以适应衣服的需要。另一个例子：在欧几里得空间中是否存在一种（任意结构的）对象的表示，使其符号属性能够很好地匹配?这可以用来描述实体及其关系，例如“罗马” $-$ “意大利” $+$ “法国” $=$ “巴黎”。
* *因果关系*（causality）和*概率图模型*（probabilistic graphical models）问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？
* *生成对抗性网络*（generative adversarial networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。

### 强化学习

如果你对使用机器学习开发与环境交互并采取行动感兴趣，那么最终可能会专注于**强化学习**（reinforcement learning）。

这可能包括应用到机器人、对话系统，甚至开发视频游戏的人工智能（AI）。

**深度强化学习**（deep reinforcement learning）将深度学习应用于强化学习的问题，是非常热门的研究领域。

突破性的深度**Q网络**（Q-network）在雅达利游戏中仅使用视觉输入就击败了人类，

以及 AlphaGo 程序在棋盘游戏围棋中击败了世界冠军，是两个突出强化学习的例子。

在强化学习问题中，智能体（agent）在一系列的时间步骤上与环境交互。

在每个特定时间点，智能体从环境接收一些**观察**（observation），并且必须选择一个**动作**（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后智能体从环境中获得**奖励**（reward）。

此后新一轮循环开始，智能体接收后续观察，并选择后续操作，依此类推。

强化学习框架的通用性十分强大。

例如，我们可以将任何监督学习问题转化为强化学习问题。

假设我们有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个“动作”。

然后，我们可以创建一个环境，该环境给予智能体的奖励。

这个奖励与原始监督学习问题的损失函数是一致的。

当然，强化学习还可以解决许多监督学习无法解决的问题。

例如，在监督学习中，我们总是希望输入与正确的标签相关联。

但在强化学习中，我们并不假设环境告诉智能体每个观测的最优动作。

一般来说，智能体只是得到一些奖励。

此外，环境甚至可能不会告诉是哪些行为导致了奖励。

# 2026.2.9

## linear-network（线性神经网络）

李沐linear-network

# 2026.2.10

休

# 2026.2.11

休

# 2026.2.12

## 张量的创建

### 依据数组创建

torch.from_numpy(ndarray)

功能：从numpy创建tensor

注意事项：从torch.from_numpy创建的tensor于原ndarray共享内存，当修改其中的一个数据时，另外一个也将会被改动

### 依据数值创建

#### torch.zeros(*size)

依size创建全0张量

size：张量的形状

#### torch.zeros_like()

依据input形状创建全0张量

#### torch.ones()

#### torch.ones_like()

创建全1

#### torch.full()

torch.full(size,fill_value，)

size：张量的形状，如（3，3）

fill_value：张量的值

#### torch.arange()

torch.arange(start = 0,end,step=1,out =None,dtype=None,layout=torch.strided,device=None，requires_grad = False)

功能：创建等差的1维张量

注意事项：区间为[start,end)

#### torch.linspace()

torch.linspace(start,end,step)

注意事项：数值区间为[start,end]

start数列起始值，end数列结束值，steps数列长度

功能：创建均分的1维张量

#### torch.logspace()

功能：创建对数均分的1维张量

注意事项：长度为steps，底为base

#### torch.eye()

功能：创建单位对角矩阵（2维张量）

注意事项：默认为方阵

n：矩阵行数 m：矩阵列数

### 依据概率分布

#### torch.normal()

torch.normal(mean,std,out= None)

功能：生成正态分布（高斯分布）

mean：均值 std：标准差

mean 和 std 既可以是标量也可以是张量

#### torch.randn()

功能：生成标准正态分布

#### torch.randn_like()

#### torch.rand()

功能：在[0,1)上生成均匀分布

#### torch.randint()

功能：区间[low,high)生成整数均匀分布

## 张量的操作：拼接，切分，索引和变换

### 拼接与切分

#### torch.cat()

torch.cat(tensors,dim=0,out=None)

功能：将张量按维度dim进行拼接

tensors：张量序列 dim：要拼接的维度

#### torch.stack()

torch.stack(tensors,dim=0,out=None)

功能：在新创建的维度dim上进行堆积 

tensors：张量序列 dim：要拼接的维度

#### torch.chunk()

torch.chunk(input,chunks,dim=0)

功能：将张量按维度dim进行平均切分

返回值：张量列表

注意事项：若不能整除，最后一份张量

小于其他张量

input：要切分的张量   chunks：要切分的份数  dim：要切分的维度

#### torch.split()

torch.split(tensor,split_size_or_sections,dim = 0)

功能：将张量按维度dim进行切分

返回值：张量列表

tensor：要切分的张量   split_size_or_sections:为int时，表示每一份的长度；为list时，按list元素切分 dim：维度

### 张量索引

#### torch.index_select()

torch.index_select(input,dim,index,out=None)

input：要索引的张量 dim：要索引的维度 index：要索引数据的序号

功能：在维度dim上，按index索引数据

返回值：依index索引数据拼接的张量

# 2026.2.13

## 张量

### 张量索引

#### torch.masked_select()

input   mask  out

功能：按mask中的True进行索引

返回值：一维张量   input：要索引的张量  mask：与input同形状的布尔类型张量

### 张量变换

#### torch.reshape()

torch.reshape(input,shape)

功能：变换张量形状   注意事项：当张量在内存中是连续时，新张量与input共享数据内存

#### torch.transpose()

input  dim0  dim1

功能：交换张量的两个维度

#### torch.t()

torch.t(input)

功能：2维张量转置，对矩阵而言，等价于torch.transpose(input,0,1)

#### torch.squeeze()

功能：压缩长度为1的维度     dim若为None，移除所有长度为1的轴；若指定维度，当且仅当该轴长度为1时，可以被移除

#### torch.unsqueeze()

功能：依据dim扩展维度

### 张量数学运算

#### 加减乘除

torch.add()  torch.addcdiv()   torch.addcmul()   torch.sub()   torch.div()  torch.mul()

torch.add(input,alpha = 1,other,out=None)逐元素计算input+alpha*other

#### 对数，指数，幂函数

torch.log() torch.exp()  torch.pow()  

#### 三角函数

torch.abs()   torch.acos()  torch.cosh()  torch.cos() torch.asin() torch.atan() torch.atan2()

## 计算图与动态图机制

### 计算图

计算图是用来描述运算的有向无环图，计算图有两个主要元素：结点Node和边Edge

结点表示数据，如向量，矩阵，张量   边表示运算，如加减乘除

计算图便于我们进行求导

### 动态图

根据计算图搭建方式，可将计算图分为动态图和静态图

动态图运算与搭建同时进行，灵活易调节

静态图先搭建图，后运算，高效但不灵活

## autograd与逻辑回归

### torch.autograd.backwardz(tensors,grad_tensors=None,retain_graph=None,create_graph=False)

功能：自动求取梯度  tensors：用于求导的张量 比如loss retain_graph：保存计算图 create：创建导数计算图，用于高阶求导 grad_tensors：多梯度权重

autograd小贴士：1.梯度不会自动清零（不断叠加）为什么要累加？直接覆盖不是更方便吗？” 这是一个为了**节省显存**而特意设计的功能，称为 **Gradient Accumulation（梯度累加）**。

假设你的显卡（RTX 3060, 6GB 显存）一次只能跑 `batch_size=16` 的数据，但你想达到 `batch_size=64` 的训练效果。

- **做法**：
  1. 跑第 1 个 batch（16张图），计算梯度（不清零）。
  2. 跑第 2 个 batch，**梯度累加**。
  3. 跑第 3 个 batch，**梯度累加**。
  4. 跑第 4 个 batch，**梯度累加**。
  5. **更新参数 (`optimizer.step()`)**。
  6. **清零梯度 (`optimizer.zero_grad()`)**。 这样，你实际上就用小显存完成了一次大 Batch 的训练。

2依赖于叶子结点的结点，requires_grad默认为True

3叶子结点不可执行in-place

 什么是叶子结点 (Leaf Node)？

在 PyTorch 的计算图（Computational Graph）中，**叶子结点**通常指的是：

- **用户直接创建的张量**（不是通过加减乘除算出来的）。
- **开启了 `requires_grad=True`**（需要求导）。

**在深度学习中，模型的可训练参数（权重 `w` 和偏置 `b`）就是典型的叶子结点。** 它们是整个计算图的“地基”。

什么是 in-place (原地) 操作？

**In-place 操作**是指：**不创建新变量，直接修改原内存地址中的数据。**

在 Python/PyTorch 中，常见的 in-place 操作有：

- 后缀带下划线的方法：`w.add_(1)`、`w.sub_(1)`、`w.mul_(2)`。
- 增强赋值运算符：`w += 1`、`w *= 2`。
- 切片赋值：`w[:] = 0`。

 数学解释

假设公式是 $y = x^2$。

我们知道导数（梯度）是 $\frac{dy}{dx} = 2x$。

- **正常情况**：
  1. 输入 $x = 3$。
  2. 计算 $y = 3^2 = 9$。
  3. 反向传播：梯度 $= 2 \times 3 = 6$。
- **In-place 捣乱情况**：
  1. 输入 $x = 3$。
  2. 计算 $y = x^2$。
  3. **突然执行 `x += 1`**（in-place），此时内存里的 $x$ 变成了 4。
  4. 反向传播：此时 PyTorch 去读 $x$ 的值，发现是 4。
  5. 梯度变成了 $2 \times 4 = 8$。**（错了！本该是 6）**

因为梯度计算往往依赖于**前向传播时的输入值**，如果输入值被“原地”篡改了，梯度就永远算不对了。

### 逻辑回归

逻辑回归是线性的二分类模型

模型表达式：

y = f（wx+b）  f（x）= 1 /（1+exp（-x））

f（x）称为Sigmoid函数，也成为Logistic函数

class = 0  0.5>y

class = 1, 0.5 <= y

线性回归是分析自变量x与因变量y（标量）之间关系的方法

逻辑回归是分析自变量x与因变量y（概率）之间关系的方法

# 2026.2.14

## Pytorch机器学习steps

```python

#===========================step 1/5 生成数据==============================
sample_nums = 100
mean_value = 1.7
bias = 1
n_data = torch.ones(sample_nums, 2)
x0 = torch.normal(mean_value * n_data, 1) + bias
y0 = torch.zeros(sample_nums)
x1 = torch.normal(-mean_value * n_data, 1) + bias
y1 = torch.ones(sample_nums)
train_x = torch.cat((x0,x1),0)
train_y = torch.cat((y0,y1),0)
#========================step 2/5 选择模型============================
class LR(nn.Module):
    def __init__(self):
        super(LR,self).__init__()
        self.features = nn.Linear(2,1)
        self.sigmoid = nn.Sigmoid()


    def forward(self,x):
        x = self.features(x)
        x = self.sigmoid(x)
        return x
lr_net = LR()#实例化逻辑回归模型
#===========================step 3/5 选择损失函数===========================
loss_fn = nn.BCELoss()

#===========================step 4/5 选择优化器=========================
lr = 0.01
optimizer = torch.optim.SGD(lr_net.parameters(), lr = lr, momentum = 0.9)
#==========================step 5/5 模型训练==============================
for iteration in range(1000):

    #前向传播
    y_pred = lr_net(train_x)

    #计算loss
    loss = loss_fn(y_pred.squeeze(),train_y)

    #计算反向传播
    loss.backward()

    #更新参数
    optimizer.step()

    #清空梯度
    optimizer.zero_grad()

    #绘图
    if iteration % 20 == 0:

        mask = y_pred.ge(0.5).float().squeeze() #以0.5的阈值进行分类
        correct = (mask == train_y).sum() #计算正确预测的样本个数
        acc = correct.item() / train_y.size(0) #

        plt.scatter(x0.data.numpy()[:,0],x0.data.numpy()[:,1],c='r',label = 'class 0')
        plt.scatter(x1.data.numpy()[:,0],x1.data.numpy()[:,1],c='r',label = 'class 1')
        
        w0,w1 = lr_net.features.weight[0]
        w0,w1 = float(w0.item()),float(w1.item())
        plot_b = float(lr_net.features.bias[0].item())
        plot_x = np.arange(-6,6,0.1)
        plot_y = (-w0 * plot_x - plot_b) / w1

        plt.xlim(-5,7)
        plt.xlim(-7,7)
        plt.plot(plot_x,plot_y)

        plt.text(-5,5,'Loss = %.4f' % loss.data.numpy(),fontdict = {'size': 20,'color': 'red'})
        plt.title("Iteration:{}\nw0:{:.2f}w1:{:.2f}b:{:.2f}accuracy:{:.2%}".format(iteration,w0,w1,plot_b,acc))
        plt.legend()

        plt.show()
        plt.pause(0.5)

        if acc > 0.9:
            break
```



## 人民币二分类

###   数据

#### 数据收集

Img，Label

#### 数据划分

train valid test

#### 数据读取

DataLoader 

Sampler ->Index         DataSet->Img,Label

1.读哪些数据？ Sampler输出的Index   Sampler决定是顺序读还是乱序读

然后DataFetcher

2.从哪读数据？ Dataset中的data_dir（数据目录）

3.怎么读数据？ Dataset中的getitem

然后collate_fn BatchData

#### 数据预处理

transforms

## DataLoader与DataSet

### torch.utils.data.DataLoader

DataLoader(dataset,batch_size = 1,shuffle = False,sampler = None,batch_sampler=None,num_workers = 0,collate_fn =None,pin_memory = False,drop_last = False,timeout=0,worker_init_fn=None,multiprocessing_context=None )

功能：构建可迭代的数据装载器

dataset:Dataset类，决定数据从哪读取，如何读取

batchsize：批大小     num_works：是否多进程读取数据  shuffle：每个epoch是否乱序  drop_last：当样本数不能被batchsize整除时，是否舍弃最后一批数据

Epoch：所有训练样本都已输入到模型之中，称为一个Epoch

Iteration：一批样本输入到模型中，称为一个Iteration

Batchsize：批大小，决定一个Epoch有多少个Iteration

样本总数：80，Batchsize：8

1Epoch = 10 Iteration

样本总数：87，Batchsize：8

1Epoch = 10Iteration ? drop_last = True

1 Epoch = 11 Iteration ? drop_last = False

### torch.utils.data.Dataset

```python
class Dataset(object):
    def __getitem__(self,index):
        raise NotImplementedError
    def __add__(self,other):
        return ConcatDataset([self,other])
```

功能：Dataset抽象类，所有自定义的Dataset需要继承它，并且复写__getitem_()  getitem()：接收一个索引，返回一个样本

## Transforms（并非Transformer）

### 运行机制

torchvision.transforms：常见的图像预处理方法

torchvision.datasets：常用数据集的dataset实现，MNIST，CIFAR-10,ImageNet等

torchvision.model：常用的模型预训练，AlexNet，VGG，ResNet，GoogLeNet等

torchvision：计算机视觉工具包

### 标准化

transforms.Normalize(mean,std,inplace=False)

功能：逐channel的对图像进行标准化   output = (input-mean)/std

mean：各通道的均值  std：各通道的标准差  inplace：是否原地操作

normalize可以加快模型训练收敛速度    可能会提高模型精度

它的作用是把原始数据变成模型能吃进去的样子

1.归一化   2.Resize   3.ToTensor

### 数据增强

数据增强又称为数据增广，数据扩增，它是对训练集进行变换，使训练集更丰富，从而让模型更具泛化能力

### 裁剪

#### transforms.CenterCrop

功能：从图像中心裁剪图片   size：裁剪后的输出尺寸

#### transforms.RandomCrop(size,padding=None,pad_if_needed=False,fill = 0,padding_mode = ‘constant’)

功能：从图片中随机裁剪出尺寸为size的图片    size：裁剪后的输出尺寸

padding：设置边缘填充大小  当为a时，上下左右均填充a个像素

当为（a，b）时，上下填充b个像素，左右填充a个像素

当为（a，b，c，d）时，左，上，右，下分别填充a，b，c，d

pad_if_need:输出size大于图像大小，则填充

#### RandomResizedCrop

功能：随机选择长宽比、面积比裁剪、并resize到输出尺寸

size：裁剪后的输出尺寸   scale：随机裁剪面积比例，默认0.08~1之间随机选

ratio：随机长宽比，默认3/4~4/3之间随机选

interpolation：插值方法   PIL.Image.NEAREST   PIL.Image.BILINEAR PIL.Image.BICUBIC

#### FiveCrop  TenCrop

功能：裁剪图像的上下左右中心五张图，输出并输出尺寸为size

TenCrop（size，vertical_flip）对这五张图片进行水平或者垂直镜像获得10张图片
